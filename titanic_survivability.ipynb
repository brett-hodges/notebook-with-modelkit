{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating ModelKits into Jupyter Notebook Workflows: A Practical Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kaggle competition, [Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic), issues a challenge to create a model that uses Titanic passenger data (name, age, price of ticket, etc) to try to predict who survived and who died.  \n",
    "\n",
    "While this Notebook does build out a solution to the problem posed, the primary goal isn't to create the best predictive model, but, instead, to demonstrate how to leverage [KitOps Modelkits](https://www.kitops.ml) within a machine learning workflow.\n",
    "\n",
    "And,though the current context applies to Jupyter Notebooks written in Python, the code provided could be used just as effectively in workflows existing outside of a Notebook environment, as well.  Also, the code's functionality could be easily reproduced in other programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If you haven't aready done so, [sign up for a free account with Jozu.ml](https://api.jozu.ml/signup)\n",
    "\n",
    "2. After you log into Jozu, add a new Repository named *\"titanic-survivability\"*, which we'll use in this Notebook.\n",
    "\n",
    "3. In the same directory as this Notebook--which we'll call the *Project directory*--create a `.env` file.\n",
    "\n",
    "4. Edit the `.env` file and add an entry for your **JOZU_USERNAME**, your **JOZU_PASSWORD** and your **JOZU_NAMESPACE** (aka your **Personal Organization** name). For example:\n",
    "```bash\n",
    "    JOZU_USERNAME=brett@jozu.org\n",
    "    JOZU_PASSWORD=my_password\n",
    "    JOZU_NAMESPACE=brett\n",
    "```\n",
    "5. Be sure to save the changes to your .env file before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Your Python Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This project was created using Python 3.12, but should work for Python versions >= 3.7.\n",
    "\n",
    "- We recommend using a Python or Conda virtual environment to isolate this project's code to prevent it from affecting the system-installed Python.\n",
    "\n",
    "- If you name your Python or Conda environment something other than \".venv\" or \"venv\", then be sure to add the name to the `.gitignore` file. *This step assumes you'll be using `git` for version control of this project.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Required Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Collated Datasets from Jozu Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the `collated-data-v1` ModelKit Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tagged ModelKit version contains the unprocessed data split into two separate datasets:  one to be used for model training, and the other to be used for model testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from kitfile_helpers import import_kitfile\n",
    "from modelkit_helpers import pull_collated_data_modelkit\n",
    "import os\n",
    "\n",
    "#construct the tag name for this ModelKit's version\n",
    "tag_name = \"collated-data-v1\"\n",
    "\n",
    "# load the login credentials to Jozu.ml taken from environment variables stored in the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# pack and push the 'collated-data-v1` ModelKit version\n",
    "pull_collated_data_modelkit(user = os.getenv(\"JOZU_USERNAME\"), \n",
    "                            passwd = os.getenv(\"JOZU_PASSWORD\"), \n",
    "                            tag = tag_name)\n",
    "\n",
    "kitfile = import_kitfile(print = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Project's Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "├── requirements.txt             # a list of python packages required for this project\n",
    "├── template\n",
    "│   └── Kitfile.template         # a base Kitfile used as a starting point\n",
    "├── docs\n",
    "│   ├── LICENSE                  # the license file \n",
    "│   └── README.md                # the project's README file\n",
    "├── titanic_survivability.ipynb  # this Jupyter Notebook\n",
    "├── Kitfile                      # the ModelKit's Kitfile to be updated via the Notebook's workflow\n",
    "└── data\n",
    "    ├── test.csv                 # the validation dataset\n",
    "    └── train.csv                # the training dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the ModelKit's Kitfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of every [ModelKit](https://kitops.ml/docs/modelkit/intro.html) is a [Kitfile](https://kitops.ml/docs/kitfile/format.html), a YAML-formatted configuration file. The Kitfile for this project has already been created with a base set of configuration details, but we'll update it as we progress through the workflow.\n",
    "\n",
    "Let's view the Kitfile's contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitfile = import_kitfile(print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `manifestVersion` and `package` sections primarily include metadata about the ModelKit.  The `docs` and `code` sections contain references to their respective project files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Collate Datasets from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data files loaded, now's a good time to update our ModelKit's Kitfile with the configuration details for the `datasets` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# load the titanic data \n",
    "train_data, test_data = [pd.read_csv(Path(\"data\") / filename) for filename in (\"train.csv\", \"test.csv\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "* **PassengerId**: a unique identifier for each passenger\n",
    "* **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "* **Pclass**: passenger class.\n",
    "* **Name**, **Sex**, **Age**: self-explanatory\n",
    "* **SibSp**: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "* **Parch**: how many children & parents of the passenger aboard the Titanic.\n",
    "* **Ticket**: ticket id\n",
    "* **Fare**: price paid (in pounds)\n",
    "* **Cabin**: passenger's cabin number\n",
    "* **Embarked**: where the passenger embarked the Titanic\n",
    "\n",
    "We want to train a model that predicts which passengers **Survived** based on the values in the other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how much data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations:\n",
    "- The **PassengerID** attribute may be used as the dataset's index\n",
    "- The **Name** and **Ticket** attributes may have some value, but they will be a bit tricky to convert into useful numbers that a model can consume. So for now, we will ignore them.\n",
    "- The **SibSp** and **Parch** attributes may be added to create the **NumRelatives** attribute\n",
    "- About 77% of the **Cabin** values are null, so we'll ignore that column, as well.\n",
    "- About 19% of the **Age** values are null, but we can replace those values with mean of the k-nearest neighbors.\n",
    "- Two of the **Embarked** values are empty, but we can replace those values with the most common value in that column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explicitly set the **PassengerId** column as the index column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.set_index(\"PassengerId\")\n",
    "test_data = test_data.set_index(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the new attribute **NumRelatives** by adding the values from **SibSp** and **Parch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"NumRelatives\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "test_data[\"NumRelatives\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Run the Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the pipeline for numerical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputer\", KNNImputer(n_neighbors=2)),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And continuing with the pipeline for the categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"ordinal_encoder\", OrdinalEncoder()),    \n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse_output=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's join the numerical and categorical pipelines and run them agains the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = [\"Age\", \"NumRelatives\", \"Fare\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])\n",
    "\n",
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "X_test = preprocess_pipeline.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export the Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save the processed datasets to disk\n",
    "np.save(Path(\"data\") / \"processed_X_train.npy\", X_train)\n",
    "np.save(Path(\"data\") / \"processed_X_test.npy\", X_test)\n",
    "y_train.to_csv(Path(\"data\") / \"processed_y_train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the Kitfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to update the Kitfile's `datasets` section to include the new processed data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitfile_helpers import update_datasets_section\n",
    "\n",
    "# add the test and train data sets to the Kitfile\n",
    "training_data_info = {\n",
    "    \"name\": \"processed_training\",\n",
    "    \"path\": \"data/processed_X_train.npy\",\n",
    "    \"description\": \"Processed data to be used for model training.\",\n",
    "    \"license\": \"Apache-2.0\"\n",
    "}\n",
    "\n",
    "testing_data_info = {\n",
    "    \"name\": \"processed_testing\",\n",
    "    \"path\": \"data/processed_X_test.npy\",\n",
    "    \"description\": \"Processed data to be used for model testing.\",\n",
    "    \"license\": \"Apache-2.0\"\n",
    "}\n",
    "\n",
    "label_data_info = {\n",
    "    \"name\": \"processed_labels\",\n",
    "    \"path\": \"data/processed_y_train.csv\",\n",
    "    \"description\": \"Processed labesl to be used for model training.\",\n",
    "    \"license\": \"Apache-2.0\"\n",
    "}\n",
    "\n",
    "datasets_info = [\n",
    "    training_data_info,\n",
    "    testing_data_info,\n",
    "    label_data_info\n",
    "]\n",
    "\n",
    "update_datasets_section(kitfile, datasets_info, replace = False, print = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push this ModelKit's Version to Jozu Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we need to update the Kitfile's `package` section with this ModelKit version's tag name and approximate timestamp that it was updated. Then display the updated Kitfile.\n",
    "\n",
    "Next, let's update the Kitfile's Package `Description` to include the tag name, `processed-data-v5`,  along with the current UTC timestamp of this update for future reference.\n",
    "\n",
    "Then, we'll pack and push the ModelKit version tagged as `processed-data-v5` to Jozu Hub.\n",
    "\n",
    "Finally, we'll print the contents of the updated Kitfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitfile_helpers import update_package_section\n",
    "from modelkit_helpers import pack_and_push_modelkit\n",
    "\n",
    "#construct the tag name for this ModelKit's version\n",
    "tag_name = \"processed-data-v5\"\n",
    "\n",
    "update_package_section(kitfile, tag_name, print = False)\n",
    "\n",
    "# load the login credentials to Jozu.ml taken from environment variables stored in the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# pack and push the 'processed-data-v5` ModelKit version\n",
    "pack_and_push_modelkit(user = os.getenv(\"JOZU_USERNAME\"), \n",
    "                       passwd = os.getenv(\"JOZU_PASSWORD\"), \n",
    "                       namespace = os.getenv(\"JOZU_NAMESPACE\"),\n",
    "                       registry = \"jozu.ml\",\n",
    "                       tag = tag_name)\n",
    "\n",
    "kitfile = import_kitfile(print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data processed, we can pack and push the ModelKit's latest state  with the tag name: `processed-data-v5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try training a `RandomForestClassifier` to predict the survivability of the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model trained, let's use it to make predictions on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the mean accuracy of 10 cross-validation folds to get an idea of how good our model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc_scores = cross_val_score(rfc, X_train, y_train, cv=10)\n",
    "rfc_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs at about 81.8% accuracy.  There are a number of things we could do to try to improve our prediction accuracy--such as *feature engineering*, *trying different types of models*, and *optimizing our models' parmameters*--but, for the purpose of this exercise, we'll assume we're ready to move our Model into production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export our trained `RandomForestClassifier` model to the joblib-formatted file named, **model.joblib**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "artifact_filename = 'model.joblib'\n",
    "\n",
    "# Save model artifact to local filesystem (doesn't persist)\n",
    "model_path = Path() / \"model\" / artifact_filename\n",
    "joblib.dump(rfc, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the Kitfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model exported, let's update our ModelKit's Kitfile with the configuration details for the `model` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitfile_helpers import update_model_section\n",
    "\n",
    "# add the `model` section to the kitfile\n",
    "model_info = {\n",
    "    \"name\": \"titanic-survivability-predictor\",\n",
    "    \"path\": str(model_path),\n",
    "    \"description\": \"RandomForestClassifier\",\n",
    "    \"framework\": \"joblib\",\n",
    "    \"license\": \"Apache-2.0\",\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "update_model_section(kitfile, model_info, print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the ModelKit to Jozu Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can tag this ModelKit version as `trained_model_v2`, pack and push it to Jozu Hub, and print the updated Kitfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the tag name for this ModelKit's version\n",
    "tag_name = \"trained_model_v2\"\n",
    "\n",
    "update_package_section(kitfile, tag_name, print = False)\n",
    "\n",
    "# load the login credentials to Jozu.ml taken from environment variables stored in the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# pack and push the 'processed-data-v5` ModelKit version\n",
    "pack_and_push_modelkit(user = os.getenv(\"JOZU_USERNAME\"), \n",
    "                       passwd = os.getenv(\"JOZU_PASSWORD\"), \n",
    "                       namespace = os.getenv(\"JOZU_NAMESPACE\"),\n",
    "                       registry = \"jozu.ml\",\n",
    "                       tag = tag_name)\n",
    "\n",
    "kitfile = import_kitfile(print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view your tagged ModelKits:\n",
    "1. Log back into [Jozu Hub](https://jozu.ml) in your browser\n",
    "2. Click on *My Repositories*\n",
    "3. Click on *titanic-survivability*\n",
    "4. Your tagged ModelKits will be displayed.\n",
    "\n",
    "You can expand each one and click the \"MORE DETAILS\" link to view information about their contents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
