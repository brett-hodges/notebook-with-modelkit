{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating ModelKits into Jupyter Notebook Workflows: A Practical Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kaggle competition, [Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic), issues a challenge to create a model that uses Titanic passenger data (name, age, price of ticket, etc) to try to predict who survived and who died.  \n",
    "\n",
    "While this Notebook does build out a solution to the problem posed, the primary goal isn't to create the best predictive model, but, instead, to demonstrate how to leverage [KitOps Modelkits](https://www.kitops.ml) within a machine learning workflow.\n",
    "\n",
    "And,though the current context applies to Jupyter Notebooks written in Python, the code provided could be used just as effectively in workflows existing outside of a Notebook environment, as well.  Also, the code's functionality could be easily reproduced in other programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If you haven't aready done so, [sign up for a free account with Jozu.ml](https://api.jozu.ml/signup)\n",
    "\n",
    "2. After you log into Jozu, add a new Repository named *\"titanic-survivability\"*, which we'll use in this Notebook.\n",
    "\n",
    "3. In the same directory as this Notebook--which we'll call the *Project directory*--create a `.env` file.\n",
    "\n",
    "4. Edit the `.env` file and add an entry for your **JOZU_USERNAME**, your **JOZU_PASSWORD** and your **JOZU_NAMESPACE** (aka your **Personal Organization** name). For example:\n",
    "```bash\n",
    "    JOZU_USERNAME=brett@jozu.org\n",
    "    JOZU_PASSWORD=my_password\n",
    "    JOZU_NAMESPACE=brett\n",
    "```\n",
    "5. Be sure to save the changes to your .env file before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Your Python Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This project was created using Python 3.12, but should work for Python versions >= 3.7.\n",
    "\n",
    "- We recommend using a Python or Conda virtual environment to isolate this project's code to prevent it from affecting the system-installed Python.\n",
    "\n",
    "- If you name your Python or Conda environment something other than \".venv\" or \"venv\", then be sure to add the name to the `.gitignore` file. *This step assumes you'll be using `git` for version control of this project.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Required Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Working with Kitfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# Helper function to print the contents of the python dictionary object\n",
    "# representing the project's Kitfile\n",
    "def print_kitfile_contents(kitfile):\n",
    "    print('\\n\\nKitfile Contents...')\n",
    "    print('===================\\n')\n",
    "    print(yaml.safe_dump(kitfile, sort_keys=False))\n",
    "\n",
    "# Helper function to read the project's Kitfile from disk into\n",
    "# a python dictionary object.\n",
    "# If the print flag is true, the Kitfile's contents are printed.\n",
    "def import_kitfile(template = False, print = True) -> dict:\n",
    "    # Path to kitfile template\n",
    "    if template:\n",
    "        kitfile_path = Path(\"template\") / \"Kitfile.template\"\n",
    "    else:\n",
    "        kitfile_path = Path() / \"Kitfile\"\n",
    "    # Open the Kitfile template\n",
    "    with open(kitfile_path, 'r') as file:\n",
    "        # Load the contents into a Python dictionary\n",
    "        kitfile = yaml.safe_load(file)\n",
    "    if print:\n",
    "        print_kitfile_contents(kitfile)\n",
    "    return kitfile\n",
    "\n",
    "# Helper function to export the python dictionary object \n",
    "# representing the project's Kitfile to disk.\n",
    "# If the print flag is true, the Kitfile's contents are printed.\n",
    "def export_kitfile(kitfile, print = True):\n",
    "    # Open the Kitfile \n",
    "    yaml.safe_dump(kitfile, open('Kitfile', 'w'), sort_keys=False)\n",
    "    if print:\n",
    "        print_kitfile_contents(kitfile)\n",
    "\n",
    "# Helper function to update the Kitfile's Code section with\n",
    "# details about the code files to include.\n",
    "# If the replace flag is True, the Code section will \n",
    "# be over-written; otherwise, the Code section will be\n",
    "# updated with the additional Code file(s).\n",
    "# If the print flag is True, the contents of the updated\n",
    "# Kitfile are printed.\n",
    "def update_code_section(kitfile, code, replace = True, print = True):\n",
    "    if replace:\n",
    "        kitfile[\"code\"] = code\n",
    "    else:\n",
    "        kitfile[\"code\"].extend(code)\n",
    "    # save the updated Kitfile contents to disk\n",
    "    export_kitfile(kitfile, print)\n",
    "\n",
    "# Helper function to update the Kitfile's Datasets section with\n",
    "# details about the data files to include.\n",
    "# If the replace flag is True, the Datasets section will \n",
    "# be over-written; otherwise, the Datasets section will be\n",
    "# updated with the additional Datasets.\n",
    "# If the print flag is True, the contents of the updated\n",
    "# Kitfile are printed.\n",
    "def update_datasets_section(kitfile, datasets, replace = True, print = True):\n",
    "    if replace:\n",
    "        kitfile[\"datasets\"] = datasets \n",
    "    else:\n",
    "        kitfile[\"datasets\"].extend(datasets)\n",
    "    # save the updated Kitfile contents to disk\n",
    "    export_kitfile(kitfile, print)\n",
    "\n",
    "# Helper function to update the Kitfile's Package section with\n",
    "# details about the current ModelKit, including the tag name\n",
    "# to be used when pushing it, and the approximate timestamp\n",
    "# when the ModelKit is to be pushed.\n",
    "# If the print flag is True, the contents of the updated\n",
    "# Kitfile are printed.\n",
    "def update_package_section(kitfile, tag_name, print = True):\n",
    "    # Get the current UTC timestamp\n",
    "    current_utc_timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "    package_section = kitfile[\"package\"]\n",
    "    description = package_section[\"description\"]\n",
    "    description += (\"\\nModelKit tag: \" + tag_name + \" pushed at: \" + current_utc_timestamp)\n",
    "    package_section[\"description\"] = description\n",
    "    # save the updated Kitfile contents to disk\n",
    "    export_kitfile(kitfile, print)\n",
    "\n",
    "# Helper function to update the Kitfile's Model section with\n",
    "# details about the trained model to include.\n",
    "# If the print flag is True, the contents of the updated\n",
    "# Kitfile are printed.\n",
    "def update_model_section(kitfile, model_info, print = True):\n",
    "    kitfile[\"model\"] = model_info\n",
    "    export_kitfile(kitfile, print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Working with ModelKits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def kit_login(user: str, passwd: str, registry: str = \"jozu.ml\"):\n",
    "    subprocess.run([\"kit\", \"login\", registry, \"-u\", user, \"--password-stdin\"], input=passwd, text=True)\n",
    "\n",
    "def kit_logout(registry: str = \"jozu.ml\"):\n",
    "    subprocess.run([\"kit\", \"logout\", registry])\n",
    "\n",
    "def kit_pull(repo_path_with_tag):\n",
    "    subprocess.run([\"kit\", \"pull\", repo_path_with_tag])\n",
    "\n",
    "def kit_pack(repo_path_with_tag: str):\n",
    "    subprocess.run([\"kit\", \"pack\", \".\", \"-t\", repo_path_with_tag])\n",
    "\n",
    "def kit_push(repo_path_with_tag):\n",
    "    subprocess.run([\"kit\", \"push\", repo_path_with_tag])\n",
    "\n",
    "def pull_collated_data_modelkit(user: str, passwd: str, namespace: str = \"jozu-demos\",\n",
    "                                registry: str = \"jozu.ml\", tag: str = \"collated-data-v1\"):\n",
    "    repo_path_with_tag = registry + \"/\" + namespace + \"/\" + \"titanic-survivability\" + \":\" + tag\n",
    "    kit_login(user, passwd, registry)\n",
    "    kit_pull(repo_path_with_tag)\n",
    "    kit_logout()\n",
    "\n",
    "def pack_and_push_modelkit(user: str, passwd: str, namespace: str, \n",
    "                           registry: str = \"jozu.ml\", tag:str = \"latest\"):\n",
    "    repo_path_with_tag = registry + \"/\" + namespace + \"/\" + \"titanic-survivability\" + \":\" + tag\n",
    "    kit_login(user, passwd, registry)\n",
    "    kit_pack(repo_path_with_tag)\n",
    "    kit_push(repo_path_with_tag)\n",
    "    kit_logout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Collated Datasets from Jozu Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the `collated-data-v1` ModelKit Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tagged ModelKit version contains the unprocessed data split into two separate datasets:  one to be used for model training, and the other to be used for model testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "#construct the tag name for this ModelKit's version\n",
    "tag_name = \"collated-data-v1\"\n",
    "\n",
    "# load the login credentials to Jozu.ml taken from environment variables stored in the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# pack and push the 'collated-data-v1` ModelKit version\n",
    "pull_collated_data_modelkit(user = os.getenv(\"JOZU_USERNAME\"), \n",
    "                            passwd = os.getenv(\"JOZU_PASSWORD\"), \n",
    "                            tag = tag_name)\n",
    "\n",
    "kitfile = import_kitfile(print = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Project's Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "├── requirements.txt             # a list of python packages required for this project\n",
    "├── template\n",
    "│   └── Kitfile.template         # a base Kitfile used as a starting point\n",
    "├── docs\n",
    "│   ├── LICENSE                  # the license file \n",
    "│   └── README.md                # the project's README file\n",
    "├── titanic_survivability.ipynb  # this Jupyter Notebook\n",
    "├── Kitfile                      # the ModelKit's Kitfile to be updated via the Notebook's workflow\n",
    "└── data\n",
    "    ├── test.csv                 # the validation dataset\n",
    "    └── train.csv                # the training dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the ModelKit's Kitfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of every [ModelKit](https://kitops.ml/docs/modelkit/intro.html) is a [Kitfile](https://kitops.ml/docs/kitfile/format.html), a YAML-formatted configuration file. The Kitfile for this project has already been created with a base set of configuration details, but we'll update it as we progress through the workflow.\n",
    "\n",
    "Let's view the Kitfile's contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitfile = import_kitfile(print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `manifestVersion` and `package` sections primarily include metadata about the ModelKit.  The `docs` and `code` sections contain references to their respective project files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Collate Datasets from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data files loaded, now's a good time to update our ModelKit's Kitfile with the configuration details for the `datasets` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# load the titanic data \n",
    "train_data, test_data = [pd.read_csv(Path(\"data\") / filename) for filename in (\"train.csv\", \"test.csv\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "* **PassengerId**: a unique identifier for each passenger\n",
    "* **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "* **Pclass**: passenger class.\n",
    "* **Name**, **Sex**, **Age**: self-explanatory\n",
    "* **SibSp**: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "* **Parch**: how many children & parents of the passenger aboard the Titanic.\n",
    "* **Ticket**: ticket id\n",
    "* **Fare**: price paid (in pounds)\n",
    "* **Cabin**: passenger's cabin number\n",
    "* **Embarked**: where the passenger embarked the Titanic\n",
    "\n",
    "We want to train a model that predicts which passengers **Survived** based on the values in the other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how much data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations:\n",
    "- The **PassengerID** attribute may be used as the dataset's index\n",
    "- The **Name** and **Ticket** attributes may have some value, but they will be a bit tricky to convert into useful numbers that a model can consume. So for now, we will ignore them.\n",
    "- The **SibSp** and **Parch** attributes may be added to create the **NumRelatives** attribute\n",
    "- About 77% of the **Cabin** values are null, so we'll ignore that column, as well.\n",
    "- About 19% of the **Age** values are null, but we can replace those values with mean of the k-nearest neighbors.\n",
    "- Two of the **Embarked** values are empty, but we can replace those values with the most common value in that column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explicitly set the **PassengerId** column as the index column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.set_index(\"PassengerId\")\n",
    "test_data = test_data.set_index(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the new attribute **NumRelatives** by adding the values from **SibSp** and **Parch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"NumRelatives\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "test_data[\"NumRelatives\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Run the Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the pipeline for numerical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputer\", KNNImputer(n_neighbors=2)),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And continuing with the pipeline for the categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"ordinal_encoder\", OrdinalEncoder()),    \n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse_output=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's join the numerical and categorical pipelines and run them agains the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = [\"Age\", \"NumRelatives\", \"Fare\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])\n",
    "\n",
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "X_test = preprocess_pipeline.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export the Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save the processed datasets to disk\n",
    "np.save(Path(\"data\") / \"processed_X_train.npy\", X_train)\n",
    "np.save(Path(\"data\") / \"processed_X_test.npy\", X_test)\n",
    "y_train.to_csv(Path(\"data\") / \"processed_y_train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the Kitfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to update the Kitfile's `datasets` section to include the new processed data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the test and train data sets to the Kitfile\n",
    "training_data_info = {\n",
    "    \"name\": \"processed_training\",\n",
    "    \"path\": \"data/processed_X_train.npy\",\n",
    "    \"description\": \"Processed data to be used for model training.\",\n",
    "    \"license\": \"Apache-2.0\"\n",
    "}\n",
    "\n",
    "testing_data_info = {\n",
    "    \"name\": \"processed_testing\",\n",
    "    \"path\": \"data/processed_X_test.npy\",\n",
    "    \"description\": \"Processed data to be used for model testing.\",\n",
    "    \"license\": \"Apache-2.0\"\n",
    "}\n",
    "\n",
    "label_data_info = {\n",
    "    \"name\": \"processed_labels\",\n",
    "    \"path\": \"data/processed_y_train.csv\",\n",
    "    \"description\": \"Processed labesl to be used for model training.\",\n",
    "    \"license\": \"Apache-2.0\"\n",
    "}\n",
    "\n",
    "datasets_info = [\n",
    "    training_data_info,\n",
    "    testing_data_info,\n",
    "    label_data_info\n",
    "]\n",
    "\n",
    "update_datasets_section(kitfile, datasets_info, replace = False, print = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push this ModelKit's Version to Jozu Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we need to update the Kitfile's `package` section with this ModelKit version's tag name and approximate timestamp that it was updated. Then display the updated Kitfile.\n",
    "\n",
    "Next, let's update the Kitfile's Package `Description` to include the tag name, `processed-data-v5`,  along with the current UTC timestamp of this update for future reference.\n",
    "\n",
    "Then, we'll pack and push the ModelKit version tagged as `processed-data-v5` to Jozu Hub.\n",
    "\n",
    "Finally, we'll print the contents of the updated Kitfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the tag name for this ModelKit's version\n",
    "tag_name = \"processed-data-v5\"\n",
    "\n",
    "update_package_section(kitfile, tag_name, print = False)\n",
    "\n",
    "# load the login credentials to Jozu.ml taken from environment variables stored in the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# pack and push the 'processed-data-v5` ModelKit version\n",
    "pack_and_push_modelkit(user = os.getenv(\"JOZU_USERNAME\"), \n",
    "                       passwd = os.getenv(\"JOZU_PASSWORD\"), \n",
    "                       namespace = os.getenv(\"JOZU_NAMESPACE\"),\n",
    "                       registry = \"jozu.ml\",\n",
    "                       tag = tag_name)\n",
    "\n",
    "kitfile = import_kitfile(print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data processed, we can pack and push the ModelKit's latest state  with the tag name: `processed-data-v5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try training a `RandomForestClassifier` to predict the survivability of the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model trained, let's use it to make predictions on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the mean accuracy of 10 cross-validation folds to get an idea of how good our model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc_scores = cross_val_score(rfc, X_train, y_train, cv=10)\n",
    "rfc_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs at about 81.8% accuracy.  There are a number of things we could do to try to improve our prediction accuracy--such as *feature engineering*, *trying different types of models*, and *optimizing our models' parmameters*--but, for the purpose of this exercise, we'll assume we're ready to move our Model into production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export our trained `RandomForestClassifier` model to the joblib-formatted file named, **model.joblib**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "artifact_filename = 'model.joblib'\n",
    "\n",
    "# Save model artifact to local filesystem (doesn't persist)\n",
    "model_path = Path() / \"model\" / artifact_filename\n",
    "joblib.dump(rfc, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the Kitfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model exported, let's update our ModelKit's Kitfile with the configuration details for the `model` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the `model` section to the kitfile\n",
    "model_info = {\n",
    "    \"name\": \"titanic-survivability-predictor\",\n",
    "    \"path\": str(model_path),\n",
    "    \"description\": \"RandomForestClassifier\",\n",
    "    \"framework\": \"joblib\",\n",
    "    \"license\": \"Apache-2.0\",\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "update_model_section(kitfile, model_info, print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the ModelKit to Jozu Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can tag this ModelKit version as `trained_model_v2`, pack and push it to Jozu Hub, and print the updated Kitfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the tag name for this ModelKit's version\n",
    "tag_name = \"trained_model_v2\"\n",
    "\n",
    "update_package_section(kitfile, tag_name, print = False)\n",
    "\n",
    "# load the login credentials to Jozu.ml taken from environment variables stored in the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# pack and push the 'processed-data-v5` ModelKit version\n",
    "pack_and_push_modelkit(user = os.getenv(\"JOZU_USERNAME\"), \n",
    "                       passwd = os.getenv(\"JOZU_PASSWORD\"), \n",
    "                       namespace = os.getenv(\"JOZU_NAMESPACE\"),\n",
    "                       registry = \"jozu.ml\",\n",
    "                       tag = tag_name)\n",
    "\n",
    "kitfile = import_kitfile(print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view your tagged ModelKits:\n",
    "1. Log back into [Jozu Hub](https://jozu.ml) in your browser\n",
    "2. Click on *My Repositories*\n",
    "3. Click on *titanic-survivability*\n",
    "4. Your tagged ModelKits will be displayed.\n",
    "\n",
    "You can expand each one and click the \"MORE DETAILS\" link to view information about their contents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
