{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating ModelKits into Jupyter Notebook Workflows: A Practical Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kaggle competition, [Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic), issues a challenge to create a model that uses Titanic passenger data (name, age, price of ticket, etc) to try to predict who survived and who died.  \n",
    "\n",
    "While this Notebook does build out a solution to the problem posed, the primary goal isn't to create the best predictive model, but, instead, to demonstrate how to leverage [KitOps Modelkits](https://www.kitops.ml) within a machine learning workflow.\n",
    "\n",
    "And,though the current context applies to Jupyter Notebooks written in Python, the code provided could be used just as effectively in workflows existing outside of a Notebook environment, as well.  Also, the code's functionality could be easily reproduced in other programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If you haven't aready done so, [sign up for a free account with Jozu.ml](https://api.jozu.ml/signup)\n",
    "\n",
    "2. After you log into Jozu, add a new Repository named *\"titanic-survivability\"*, which we'll use in this Notebook.\n",
    "\n",
    "3. In the same directory as this Notebook--which we'll call the *Project directory*--create a `.env` file.\n",
    "\n",
    "4. Edit the `.env` file and add an entry for your **JOZU_USERNAME**, your **JOZU_PASSWORD** and your **JOZU_NAMESPACE** (aka your **Personal Organization** name). For example:\n",
    "```bash\n",
    "    JOZU_USERNAME=brett@jozu.org\n",
    "    JOZU_PASSWORD=my_password\n",
    "    JOZU_NAMESPACE=brett\n",
    "```\n",
    "5. Be sure to save the changes to your .env file before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Your Python Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This project was created using Python 3.12, but should work for Python versions >= 3.7.\n",
    "\n",
    "- We recommend using a Python or Conda virtual environment to isolate this project's code to prevent it from affecting the system-installed Python.\n",
    "\n",
    "- If you name your Python or Conda environment something other than \".venv\" or \"venv\", then be sure to add the name to the `.gitignore` file. *This step assumes you'll be using `git` for version control of this project.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Required Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (3.9.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.1.2)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.5.2)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (4.66.5)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (8.1.5)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (6.0.2)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 1)) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 1)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 7)) (8.28.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 7)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./.venv/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 7)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./.venv/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 7)) (3.0.13)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Working with Kitfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Helper function to read the project's Kitfile from disk into\n",
    "# a python dictionary object\n",
    "def import_kitfile() -> dict:\n",
    "    # Path to kitfile template\n",
    "    kitfile_template = Path(\"template\") / \"Kitfile.template\"\n",
    "    # Open the Kitfile template\n",
    "    with open(kitfile_template, 'r') as file:\n",
    "        # Load the contents into a Python dictionary\n",
    "        kitfile = yaml.safe_load(file)\n",
    "    return kitfile\n",
    "\n",
    "# Helper function to export the python dictionary object \n",
    "# representing the project's Kitfile to disk\n",
    "def export_kitfile(kitfile):\n",
    "    # Open the Kitfile \n",
    "    yaml.safe_dump(kitfile, open('Kitfile', 'w'), sort_keys=False)\n",
    "\n",
    "# Helper function to print the contents of the python dictionary object\n",
    "# representing the project's Kitfile\n",
    "def print_kitfile_contents(kitfile):\n",
    "    print('Kitfile Contents...')\n",
    "    print('===================\\n')\n",
    "    print(yaml.safe_dump(kitfile, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Working with ModelKits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def kit_login(user: str, passwd: str, registry: str = \"jozu.ml\"):\n",
    "    subprocess.run([\"kit\", \"login\", registry, \"-u\", user, \"--password-stdin\"], input=passwd, text=True)\n",
    "\n",
    "def kit_logout(registry: str = \"jozu.ml\"):\n",
    "    subprocess.run([\"kit\", \"logout\", registry])\n",
    "\n",
    "def kit_pack(repo_path_with_tag: str):\n",
    "    subprocess.run([\"kit\", \"pack\", \".\", \"-t\", repo_path_with_tag])\n",
    "\n",
    "def kit_push(repo_path_with_tag):\n",
    "    subprocess.run([\"kit\", \"push\", repo_path_with_tag])\n",
    "\n",
    "def pack_and_push_modelkit(user: str, passwd: str, namespace: str, \n",
    "                           registry: str = \"jozu.ml\", tag:str = \"latest\"):\n",
    "    repo_path_with_tag = registry + \"/\" + namespace + \"/\" + \"titanic-survivability\" + \":\" + tag\n",
    "    kit_login(user, passwd, registry)\n",
    "    kit_pack(repo_path_with_tag)\n",
    "    kit_push(repo_path_with_tag)\n",
    "    kit_logout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Project's Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "├── requirements.txt             # a list of python packages required for this project\n",
    "├── template\n",
    "│   └── Kitfile.template         # a base Kitfile used as a starting point\n",
    "├── docs\n",
    "│   ├── LICENSE                  # the license file \n",
    "│   └── README.md                # the project's README file\n",
    "├── titanic_survivability.ipynb  # this Jupyter Notebook\n",
    "├── Kitfile                      # the ModelKit's Kitfile to be updated via the Notebook's workflow\n",
    "└── data\n",
    "    ├── test.csv                 # the validation dataset\n",
    "    └── train.csv                # the training dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the ModelKit's Kitfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of every [ModelKit](https://kitops.ml/docs/modelkit/intro.html) is a [Kitfile](https://kitops.ml/docs/kitfile/format.html), a YAML-formatted configuration file. The Kitfile for this project has already been created with a base set of configuration details, but we'll update it as we progress through the workflow.\n",
    "\n",
    "Let's view the Kitfile's contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kitfile Contents...\n",
      "===================\n",
      "\n",
      "manifestVersion: 1.0\n",
      "package:\n",
      "  name: Titanic-Survivability-Predictor\n",
      "  version: 1.0.0\n",
      "  description: A project attempting to predict passenger survivability of the Titanic\n",
      "    Shipwreck.\n",
      "  authors:\n",
      "  - Jozu\n",
      "docs:\n",
      "- path: docs/README.md\n",
      "  description: Important notes about the project.\n",
      "- path: docs/LICENSE\n",
      "  description: The license for this ModelKit\n",
      "code:\n",
      "- path: requirements.txt\n",
      "  description: Python packages required by this example.\n",
      "  license: Apache-2.0\n",
      "- path: titanic_survivability.ipynb\n",
      "  description: Jupyter Notebook used to train, validate, optimize and export the model.\n",
      "  license: Apache-2.0\n",
      "- path: template/Kitfile.template\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kitfile = import_kitfile()\n",
    "print_kitfile_contents(kitfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `manifestVersion` and `package` sections primarily include metadata about the ModelKit.  The `docs` and `code` sections contain references to their respective project files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# load the titanic data \n",
    "train_data, test_data = [pd.read_csv(Path(\"data\") / filename) for filename in (\"train.csv\", \"test.csv\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the Kitfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the datasets to the Kitfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data files loaded, now's a good time to update our ModelKit's Kitfile with the configuration details for the `datasets` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kitfile Contents...\n",
      "===================\n",
      "\n",
      "manifestVersion: 1.0\n",
      "package:\n",
      "  name: Titanic-Survivability-Predictor\n",
      "  version: 1.0.0\n",
      "  description: A project attempting to predict passenger survivability of the Titanic\n",
      "    Shipwreck.\n",
      "  authors:\n",
      "  - Jozu\n",
      "docs:\n",
      "- path: docs/README.md\n",
      "  description: Important notes about the project.\n",
      "- path: docs/LICENSE\n",
      "  description: The license for this ModelKit\n",
      "code:\n",
      "- path: requirements.txt\n",
      "  description: Python packages required by this example.\n",
      "  license: Apache-2.0\n",
      "- path: titanic_survivability.ipynb\n",
      "  description: Jupyter Notebook used to train, validate, optimize and export the model.\n",
      "  license: Apache-2.0\n",
      "- path: template/Kitfile.template\n",
      "datasets:\n",
      "- name: training\n",
      "  path: data/train.csv\n",
      "  description: Unprocessed data to be used for model training.\n",
      "  license: Apache-2.0\n",
      "- name: testing\n",
      "  path: data/test.csv\n",
      "  description: Unprocessed data to be used for model testing.\n",
      "  license: Apache-2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add the test and train data sets to the Kitfile\n",
    "training_data_info = {\n",
    "    \"name\": \"training\",\n",
    "    \"path\": \"data/train.csv\",\n",
    "    \"description\": \"Unprocessed data to be used for model training.\",\n",
    "    \"license\": \"Apache-2.0\"\n",
    "}\n",
    "\n",
    "testing_data_info = {\n",
    "    \"name\": \"testing\",\n",
    "    \"path\": \"data/test.csv\",\n",
    "    \"description\": \"Unprocessed data to be used for model testing.\",\n",
    "    \"license\": \"Apache-2.0\"\n",
    "}\n",
    "\n",
    "datasets_info = [\n",
    "    training_data_info,\n",
    "    testing_data_info\n",
    "]\n",
    "\n",
    "kitfile[\"datasets\"] = datasets_info \n",
    "\n",
    "# save the updated Kitfile contents to disk\n",
    "export_kitfile(kitfile)\n",
    "\n",
    "# display the Kitfile's content\n",
    "print_kitfile_contents(kitfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push this ModelKit's Version to Jozu Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Kitfile updated to include the raw data, now's a good time to push the ModelKit to Jozu Hub, tagged as `collated-data-v1`.  However, before this is done, the Kitfile's Package `Description` will be updated to include the current UTC date and time for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kitfile Contents...\n",
      "===================\n",
      "\n",
      "manifestVersion: 1.0\n",
      "package:\n",
      "  name: Titanic-Survivability-Predictor\n",
      "  version: 1.0.0\n",
      "  description: 'A project attempting to predict passenger survivability of the Titanic\n",
      "    Shipwreck.\n",
      "\n",
      "    ModelKit tag: collated-data-v1 pushed at: 2024-10-21 15:34:38 UTC'\n",
      "  authors:\n",
      "  - Jozu\n",
      "docs:\n",
      "- path: docs/README.md\n",
      "  description: Important notes about the project.\n",
      "- path: docs/LICENSE\n",
      "  description: The license for this ModelKit\n",
      "code:\n",
      "- path: requirements.txt\n",
      "  description: Python packages required by this example.\n",
      "  license: Apache-2.0\n",
      "- path: titanic_survivability.ipynb\n",
      "  description: Jupyter Notebook used to train, validate, optimize and export the model.\n",
      "  license: Apache-2.0\n",
      "- path: template/Kitfile.template\n",
      "datasets:\n",
      "- name: training\n",
      "  path: data/train.csv\n",
      "  description: Unprocessed data to be used for model training.\n",
      "  license: Apache-2.0\n",
      "- name: testing\n",
      "  path: data/test.csv\n",
      "  description: Unprocessed data to be used for model testing.\n",
      "  license: Apache-2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "#construct the tag name for this ModelKit's version\n",
    "tag_name = \"collated-data-v1\"\n",
    "\n",
    "# Get the current UTC timestamp formatted in compliance with the OCI Specification\n",
    "# for allowed characters in tag names\n",
    "current_utc_timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "package_section = kitfile[\"package\"]\n",
    "description = package_section[\"description\"]\n",
    "description += (\"\\n\" + \"ModelKit tag: \" + tag_name + \" pushed at: \" + current_utc_timestamp)\n",
    "package_section[\"description\"] = description\n",
    "\n",
    "# save the updated Kitfile contents to disk\n",
    "export_kitfile(kitfile)\n",
    "\n",
    "# display the Kitfile's content\n",
    "print_kitfile_contents(kitfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pack and push the ModelKit version tagged as `collated-data-v1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log in successful\n",
      "Saved configuration: sha256:c847ab63bf074e18ef3bc8ade6449c70076a02e39259ecb14d95187625e81770\n",
      "Already saved code layer: sha256:9de9f1238dd7a623c617cbc14e7f5eada59d28085909e9cf57279ce0ebd6a5ee\n",
      "Saved code layer: sha256:ccd7f1227006a7a0e196305cfc461d85f0321f2e9e378cfeb402df435df29acf\n",
      "Saved code layer: sha256:220109bcd4dc8be72b9228aefb24f69239c3308297cb4a4806705c002e910e3c\n",
      "Already saved dataset layer: sha256:8af74261fda984270cc30a58277f28c3435de603ba2722e160528a0fab6d1127\n",
      "Already saved dataset layer: sha256:cbd1c99ae96851ca944aeda77e1e8338c00fd639b9cdcdbe42044ec99352cb79\n",
      "Saved docs layer: sha256:7de63cef90f75c857e373367403ad0a23143068b62e5b725c02f845043df6c8c\n",
      "Already saved docs layer: sha256:0b45ae1c1fe73e1bcc537625392baeb70253f551ab2b3ee384b214fbf82c2be7\n",
      "Saved manifest to storage: sha256:8b634e1814dee82b06947427943f420ed63adba7423a413f8c7f007ed2aafc06\n",
      "Model saved: sha256:8b634e1814dee82b06947427943f420ed63adba7423a413f8c7f007ed2aafc06\n",
      "Pushing jozu.ml/brett/titanic-survivability:collated-data-v1\n",
      "Pushed sha256:8b634e1814dee82b06947427943f420ed63adba7423a413f8c7f007ed2aafc06\n",
      "Successfully logged out from jozu.ml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load the login credentials to Jozu.ml taken from environment variables stored in the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# pack and push the 'collated-data-v1` ModelKit version\n",
    "pack_and_push_modelkit(user = os.getenv(\"JOZU_USERNAME\"), \n",
    "                       passwd = os.getenv(\"JOZU_PASSWORD\"), \n",
    "                       namespace = os.getenv(\"JOZU_NAMESPACE\"),\n",
    "                       registry = \"jozu.ml\",\n",
    "                       tag = tag_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "* **PassengerId**: a unique identifier for each passenger\n",
    "* **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "* **Pclass**: passenger class.\n",
    "* **Name**, **Sex**, **Age**: self-explanatory\n",
    "* **SibSp**: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "* **Parch**: how many children & parents of the passenger aboard the Titanic.\n",
    "* **Ticket**: ticket id\n",
    "* **Fare**: price paid (in pounds)\n",
    "* **Cabin**: passenger's cabin number\n",
    "* **Embarked**: where the passenger embarked the Titanic\n",
    "\n",
    "We want to train a model that predicts which passengers **Survived** based on the values in the other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explicitly set the **PassengerId** column as the index column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.set_index(\"PassengerId\")\n",
    "test_data = test_data.set_index(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how much data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations:\n",
    "- The **Name** and **Ticket** attributes may have some value, but they will be a bit tricky to convert into useful numbers that a model can consume. So for now, we will ignore them.\n",
    "- About 77% of the **Cabin** values are null, so we'll ignore that column, as well.\n",
    "- About 19% of the **Age** values are null, but we can replace those values with the median Age.\n",
    "- Two of the **Embarked** values are empty, but we can replace those values with the most common value in that column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Run the Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the pipeline for numerical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And continuing with the pipeline for the categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"ordinal_encoder\", OrdinalEncoder()),    \n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse_output=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's join the numerical and categorical pipelines and run them agains the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])\n",
    "\n",
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try training a `RandomForestClassifier` to predict the survivability of the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model trained, let's use it to make predictions on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess_pipeline.transform(test_data)\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the mean accuracy of 10 cross-validation folds to get an idea of how good our model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc_scores = cross_val_score(rfc, X_train, y_train, cv=10)\n",
    "rfc_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs at about 81.6% accuracy.  There are a number of things we could do to try to improve our prediction accuracy--such as *feature engineering*, *trying different types of models*, and *optimizing our models' parmameters*--but, for the purpose of this exercise, we'll assume we're ready to move our Model into production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export our trained `RandomForestClassifier` model to the joblib-formatted file named, **model.joblib**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "artifact_filename = 'model.joblib'\n",
    "\n",
    "# Save model artifact to local filesystem (doesn't persist)\n",
    "model_path = Path() / \"model\" / artifact_filename\n",
    "joblib.dump(rfc, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the Kitfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model exported, let's update our ModelKit's Kitfile with the configuration details for the `model` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the 'images' folder to the 'docs' section of the Kitfile\n",
    "model_info = {\n",
    "    \"name\": \"titanic-survivability-predictor\",\n",
    "    \"path\": str(model_path),\n",
    "    \"description\": \"RandomForestClassifier\",\n",
    "    \"framework\": \"joblib\",\n",
    "    \"license\": \"Apache-2.0\",\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "kitfile[\"model\"] = model_info\n",
    "\n",
    "# save the updated Kitfile contents to disk\n",
    "export_kitfile(kitfile)\n",
    "\n",
    "# reload the Kitfile from disk and display the contents\n",
    "# to make sure it was persisited correctly\n",
    "print_kitfile_contents(kitfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Pushing the ModelKit to Jozu Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can pack and push our final ModelKit to Jozu Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# the login credentials to Jozu.ml taken from environment variables stored in the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "pack_and_push_modelkit(user = os.getenv(\"JOZU_USERNAME\"), \n",
    "                       passwd = os.getenv(\"JOZU_PASSWORD\"), \n",
    "                       namespace = os.getenv(\"JOZU_NAMESPACE\"),\n",
    "                       registry = \"jozu.ml\",\n",
    "                       tag = \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log back into [Jozu Hub](https://jozu.ml) in your browser, click on *My Repositories* and you should see your ModelKit tagged as \"latest\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
